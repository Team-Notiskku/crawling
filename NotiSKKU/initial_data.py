from playwright.sync_api import sync_playwright
from urllib.parse import urljoin
from googleapiclient.discovery import build
from google.oauth2 import service_account

SERVICE_ACCOUNT_FILE = "notiskku-449608-4c2aa194efc2.json" ## ë³‘í•© ì‹œ ìˆ˜ì • í•„ìš” (credentials.json)
SCOPES = ["https://www.googleapis.com/auth/spreadsheets"]
SPREADSHEET_ID = "1rn5W6x50T9H0Nijobqwi616Le77j3nrBACfDXDqVsjA"  ## ë³‘í•© ì‹œ ìˆ˜ì • í•„ìš” (1RPTHVpyEJb4mZs9sz10E5OwIpZB-3YJcfrg5H7dFqhM)
SHEET_NAME = "ì „ì²´ ê³µì§€"  ## ì „ì²´ / ë‹¨ê³¼ëŒ€ / í•™ê³¼ ë³„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ êµ¬í˜„ ì˜ˆì •

creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)
service = build("sheets", "v4", credentials=creds)

def update_google_sheets(data):
    """í¬ë¡¤ë§í•œ ë°ì´í„°ë¥¼ Google Sheetsì— ì—…ë¡œë“œ"""
    range_name = f"{SHEET_NAME}!A1"
    body = {"values": data}
    
    service.spreadsheets().values().update(
        spreadsheetId=SPREADSHEET_ID,
        range=range_name,
        valueInputOption="RAW",
        body=body
    ).execute()
    print("âœ… Google Sheets ì—…ë°ì´íŠ¸ ì™„ë£Œ!")


def get_notice():
    base_url = "https://www.skku.edu/skku/campus/skk_comm/notice01.do"
    max_pages = 10 
    
    notices = [["ID", "category", "title", "date", "uploader", "views", "link"]]

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        for page_num in range(max_pages):
            offset = page_num * 10
            notice_url = f"?mode=list&&articleLimit=10&article.offset={offset}"
            full_url = urljoin(base_url, notice_url)
            
            print(f"ğŸ“¢ í˜ì´ì§€ {page_num + 1} (offset={offset}) í¬ë¡¤ë§ ì¤‘...")
            page.goto(full_url)
            page.wait_for_load_state("load")

            for i in range(1, 11):
                try:
                    id = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dd/ul/li[1]').inner_text(timeout=1000)
                    category = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dt/span[1]').inner_text(timeout=1000)
                    title = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dt/a').inner_text(timeout=1000)
                    date = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dd/ul/li[3]').inner_text(timeout=1000)
                    uploader = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dd/ul/li[2]').inner_text(timeout=1000)
                    views = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dd/ul/li[4]/span').inner_text(timeout=1000)
                    link = page.locator(f'//*[@id="jwxe_main_content"]/div/div/div[1]/div[1]/ul/li[{i}]/dl/dt/a').get_attribute("href")
                    
                    id = id[3:] 
                    link = urljoin(base_url, link)

                    notices.append([id, category, title, date, uploader, views, link])

                except Exception as e:
                    print(f"âŒ {i}ë²ˆ ê³µì§€ í¬ë¡¤ë§ ì˜¤ë¥˜ ë°œìƒ: {e}")

        browser.close()

        notices[1:] = sorted(notices[1:], key=lambda x: x[0])

    return notices


notices_data = get_notice()
if notices_data:
    update_google_sheets(notices_data)
else:
    print("âŒ í¬ë¡¤ë§ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")